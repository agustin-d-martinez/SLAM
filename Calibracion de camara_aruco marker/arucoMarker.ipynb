{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd1a6e3",
   "metadata": {},
   "source": [
    "# Obtención de Dataset\n",
    "\n",
    "Pasos:\n",
    "1. Colocar 4 arauco en las esquinas.\n",
    "2. Medir y calibrar la cámara.\n",
    "3. Detectar el robot con un 5to arauco distinto.\n",
    "4. Detectar muros/contornos con threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb664d1",
   "metadata": {},
   "source": [
    "# Prueba de detección de Aruco Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092a9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Cámara:\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Diccionarios y detectores Aruco Markers:\n",
    "aruco_dict = cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_100)\n",
    "parameters = cv.aruco.DetectorParameters()\n",
    "detector = cv.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detección de ArUco\n",
    "    corners, ids, rejected = detector.detectMarkers(frame)\n",
    "\n",
    "    if ids is not None:\n",
    "        cv.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        for i, corner in enumerate(corners):\n",
    "            c = corner[0]\n",
    "            # Coordenadas del centro\n",
    "            x_corner = int((c[:,0].mean()))\n",
    "            y_center = int((c[:,1].mean()))\n",
    "            cv.circle(frame, (x_corner, y_center), 5, (0,0,255), -1)\n",
    "\n",
    "            print(f\"Marker {ids[i]} en píxeles: ({x_corner},{y_center})\")\n",
    "\n",
    "    cv.imshow(\"Frame\", frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960f715",
   "metadata": {},
   "source": [
    "# Calibración de Cámara\n",
    "\n",
    "Instrucciones de uso:\n",
    "\n",
    "* Colocar en chess_size las dimensiones del tablero de ajedrez (es decir, la cantida de cuadrados en x e y)\n",
    "* Colocar el tamaño de cada casilla en mm. Como son cuadradas por definición, solo se requiere el largo.\n",
    "\n",
    "\n",
    "*  Se obtienen las variables: ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "ret: Error de retención. (RMS de error general de la cámara).\n",
    "\n",
    "mtx: Matriz de la cámara. (Matriz de la cámara. 3x3. Indica parámetros propios como el focal lenght).\n",
    "\n",
    "dist: Coeficientes de distorción. **IMPORTANTE** (Array de 5 valores para corrección de la cámara. 3 de distorción radial y 2 de distorción tangencial).\n",
    "\n",
    "rvecs: Vector de rotación. (Matriz de rotación de la imagen. Permite corregir la rotación).\t**IRRELEVANTE**\n",
    "\n",
    "tvecs: Vector de traslación. (Matriz de traslación de la imagen. Permite corregir la posición de la imagen).**IRRELEVANTE**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "\n",
    "###### VARIABLES ###########################################################\n",
    "chess_size = (9,6)\t\t\t\t\t# Dimensiones de tablero patrón\n",
    "chess_square_lenght = 30.0  \t\t# En mm\n",
    "\n",
    "calib_img_path = 'calibration_images'\n",
    "test_img_path = 'test_images'\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "# Vector de posiciones de esquinas:\n",
    "corner_size = (chess_size[0]-1, chess_size[1]-1)    #Las funciones utilizan las esquinas internas, no la cant de cuadrados\n",
    "objp = np.zeros((corner_size[0]*corner_size[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:corner_size[0],0:corner_size[1]].T.reshape(-1,2)\n",
    "objp *= chess_square_lenght\n",
    "\n",
    "objpoints = [] # puntos 3D en el mundo real\n",
    "imgpoints = [] # puntos 2D en la imagen\n",
    "\n",
    "images = glob.glob(f'{calib_img_path}/*.jpg')\n",
    "\n",
    "if not images:\n",
    "    print(\"No hay imagenes.\")\n",
    "    sys.exit()\n",
    "if len(images) < 10:\n",
    "    print(\"Advertencia. Pocas imágenes. Se recomiendan 10 o más en distintos ángulos\")\n",
    "\n",
    "for fname in images:\n",
    "    print(f\"Probando foto {fname}\")\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\t\t# Lo pasa a escala de grises para mejorar\n",
    "    ret, corners = cv.findChessboardCornersSB(gray, corner_size, None)\n",
    "    \n",
    "    if ret == True:\n",
    "        print(f\"Encontrado en {fname}\")\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        cv.drawChessboardCorners(img, corner_size, corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "if not ret:\n",
    "    print(\"No se encontró nada.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Calibración\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Matriz intrínseca:\\n\", mtx)\n",
    "print(\"Coeficientes de distorsión:\\n\", dist)\n",
    "np.savez(\"calibration_values\", mtx=mtx, dist=dist)\n",
    "\n",
    "# Verificacion\n",
    "images = glob.glob(f'{test_img_path}/*.jpg')\n",
    "\n",
    "if not images:\n",
    "    print(\"No hay imagenes para verificar.\")\n",
    "    sys.exit()\n",
    "\n",
    "for fname in images:\n",
    "    print(f\"Corrigiendo {fname}\")\n",
    "    img = cv.imread(fname)\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    # Elimina distorcion\n",
    "    dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    " \n",
    "    # Recorte de la imagen\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    name = os.path.basename(fname)\n",
    "    cv.imwrite(f\"{test_img_path}/{name}_calib.jpg\", dst)\n",
    "    print(f\"{fname} corregido y guardado en test_iamges/{name}_calib.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calib_img(img, mtx, dist):\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    # Elimina distorcion\n",
    "    undistorted = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    " \n",
    "    # Recorte de la imagen\n",
    "    x, y, w, h = roi\n",
    "    undistorted = undistorted[y:y+h, x:x+w]\n",
    "    return undistorted\n",
    "\n",
    "def load_calib_matrix(file):\n",
    "    try:\n",
    "        calib = np.load(f\"{file}.npz\")\n",
    "        mtx, dist = calib[\"mtx\"], calib[\"dist\"]\n",
    "    except Exception as e:\n",
    "        mtx, dist = None, None\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed95dd8",
   "metadata": {},
   "source": [
    "# Medición de distancia Aruco Marker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b3992",
   "metadata": {},
   "source": [
    "Prueba 1:\n",
    "\n",
    "\n",
    "El marker size es 100mm pero no me devuelve el Z correcto. Me devuelve el doble. Con marker size de 50 funciona bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "###### VARIABLES ###########################################################\n",
    "marker_size = 50  # mm\n",
    "\n",
    "#######################################################################################\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "### Creación del diccionario y detector\n",
    "aruco_dict = cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_100)\n",
    "parameters = cv.aruco.DetectorParameters()\n",
    "detector = cv.aruco.ArucoDetector(aruco_dict, parameters)\n",
    "\n",
    "### Carga de la Matriz de calibracion\n",
    "mtx, dist = load_calib_matrix(\"calibration_values\")\n",
    "\n",
    "if mtx is None or dist is None:\n",
    "    print(\"Faltan valores de calibracion\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "### Loop de lectura de video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detección de ArUco. NOTA: La funcion detecta todos los ArUco en pantalla y los pasa como lista con los ID.\n",
    "    # corners[i][0][corner_num] -> (xi, yi)\n",
    "    # ids[i] -> id del marker i\n",
    "    corners, ids, _ = detector.detectMarkers(frame)\n",
    "\n",
    "    if ids is not None:\n",
    "        # tvecs[i][0] -> (x,y,z)\n",
    "        rvecs, tvecs, _ = cv.aruco.estimatePoseSingleMarkers(corners, marker_size, mtx, dist)\n",
    "\n",
    "        cv.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            cv.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "            # Dibujar ejes\n",
    "            cv.drawFrameAxes(frame, mtx, dist, rvecs[i], tvecs[i], 50)\n",
    "            \n",
    "            # Mostrar distancia Z (en mm)\n",
    "            x, y, z = tvecs[i][0]\n",
    "\n",
    "            print(f\"marcador {ids[i]} en (x:{x:.2f},y:{x:.2f},z:{z:.2f})\")\n",
    "\n",
    "            x_corner = int(corners[i][0][3][0])\n",
    "            y_corner = int(corners[i][0][3][1])\n",
    "            \n",
    "            \n",
    "            #print(f\"Marker {ids[i]} a {distancia:.1f} mm de la cámara\")\n",
    "\n",
    "            cv.putText(frame, f\"Z: {z:.1f}\",(x_corner, y_corner - 10),                       \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, \n",
    "                       0.8, \n",
    "                       (255, 0, 0), \n",
    "                       2, \n",
    "                       cv.LINE_AA)\n",
    "\n",
    "    cv.imshow(\"Frame\", frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb0feb",
   "metadata": {},
   "source": [
    "Prueba 2: (El código fue sacado del siguiente [link](https://visionbrick.com/measuring-depth-from-a-single-camera-using-aruco-markers-in-opencv/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5256fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" \n",
    "load your camera’s intrinsic matrix and distortion coefficients from a YAML file\n",
    "- camera_matrix is the 3×3 intrinsic parameters matrix.\n",
    "- dist_coeffs holds lens distortion parameters.\n",
    "- marker_length is the side length of the ArUco marker in meters.\n",
    "\"\"\"\n",
    "camera_matrix, dist_coeffs = load_calib_matrix(\"calibration_values\")\n",
    "marker_length = 100  # mm\n",
    " \n",
    "\"\"\"\n",
    "DICT_4X4_50 is a predefined dictionary of ArUco markers.\n",
    "4x4 markers with 50 unique IDs.(16 bits per marker)\n",
    "parameters are the default detection parameters.\n",
    "\"\"\"\n",
    "aruco_dict = cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_100)\n",
    "parameters = cv.aruco.DetectorParameters()\n",
    " \n",
    "# create a detector instance with default parameters.\n",
    "detector = cv.aruco.ArucoDetector(aruco_dict, parameters)\n",
    " \n",
    "cap = cv.VideoCapture(0)\n",
    " \n",
    "num=0\n",
    " \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    " \n",
    "    # Detect markers in the frame with detectMarkers method\n",
    "    corners, ids, _ = detector.detectMarkers(frame)\n",
    "    \"\"\"\n",
    "    Example output of corners:\n",
    "    (array([[[ 15., 339.],\n",
    "        [ 91., 334.],\n",
    "        [ 98., 404.],\n",
    "        [ 19., 414.]]], dtype=float32),)\n",
    "    \"\"\"\n",
    " \n",
    "    if ids is not None and len(ids) > 0:\n",
    "        cv.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    " \n",
    "        # Define the 3D coordinates of the marker corners in the marker's coordinate system\n",
    "        obj_points = np.array([\n",
    "            [-marker_length / 2,  marker_length / 2, 0],\n",
    "            [ marker_length / 2,  marker_length / 2, 0],\n",
    "            [ marker_length / 2, -marker_length / 2, 0],\n",
    "            [-marker_length / 2, -marker_length / 2, 0]\n",
    "        ], dtype=np.float32)\n",
    " \n",
    "         \n",
    "        for marker_corners in corners:\n",
    "            image_points = marker_corners[0].astype(np.float32)\n",
    " \n",
    "            \"\"\"\n",
    "            solvePnP estimates the pose of a 3D object given its 3D points and corresponding 2D image points.\n",
    "            It returns the rotation vector (rvec) and translation vector (tvec).\n",
    "            \"\"\"\n",
    "            retval, rvec, tvec = cv.solvePnP(obj_points, image_points, camera_matrix, dist_coeffs)\n",
    "             \n",
    "            if retval:\n",
    "                # Draw the axis on the frame\n",
    "                cv.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvec, tvec, 0.03)\n",
    "                 \n",
    "                # Extract the translation vector and calculate the distance\n",
    "                x, y, z = tvec.flatten()\n",
    "                distance = np.linalg.norm(tvec)\n",
    "                \n",
    "                # Print to terminal\n",
    "                print(f\"X={x:.3f} m, Y={y:.3f} m, Z(depth)={z:.3f} m, Distance={distance:.3f} m\")\n",
    "                \n",
    "                # Display on frame with different colors\n",
    "                org = (20, 40)  \n",
    "                font = cv.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.7\n",
    "                thickness = 2\n",
    "                cv.putText(frame, f\"X={x:.3f} mm\", (org[0], org[1]), font, font_scale, (0, 255, 0), thickness, cv.LINE_AA)\n",
    "                cv.putText(frame, f\"Y={y:.3f} mm\", (org[0], org[1]+30), font, font_scale, (255, 0, 0), thickness, cv.LINE_AA)\n",
    "                cv.putText(frame, f\"Depth={z:.3f} mm\", (org[0], org[1]+60), font, font_scale, (0, 0, 255), thickness, cv.LINE_AA)\n",
    "                cv.putText(frame, f\"Dist={distance:.3f} mm\", (org[0], org[1]+90), font, font_scale, (0, 255, 255), thickness, cv.LINE_AA)\n",
    " \n",
    "    # Display the frame with detected markers and pose estimatio\n",
    "    cv.imshow('ArUco Pose Estimation', frame)\n",
    "      \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6984679",
   "metadata": {},
   "source": [
    "# Rectificación de la foto\n",
    "\n",
    "Utilizando 4 ArUco Markers se busca que el plano quede totalmente perpendicular. Este código debería ajustar eso y ver \"desde arriba\" al plano.\n",
    "\n",
    "Se le conoce como **Homografía**.\n",
    "\n",
    "\n",
    "Este código utiliza 4 ID's distintas. Una para cada esquina. Podría mejorarse a 1 sola cambiando:\n",
    "```python:\n",
    "    if marker_id in corner_ids:\n",
    "```\n",
    "\n",
    "Por:\n",
    "```python:\n",
    "    if marker_id == corner_id:\n",
    "```\n",
    "\n",
    "Y también cambiar:\n",
    "```python:\n",
    "    if all(mid in detected for mid in corner_ids)\n",
    "```\n",
    "\n",
    "Por:\n",
    "```python:\n",
    "    if (detected.len() == 4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf188204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "## Variables:\n",
    "calib_value_file = \"calibration_values\"\n",
    "\n",
    "plane_size = (300, 200)     # En mm\n",
    "image_size = (600, 600)     # Tamaño de la hoja En pixeles.\n",
    "\n",
    "scale = plane_size / image_size\n",
    "\n",
    "## Código:\n",
    "mtx, dist = load_calib_matrix(calib_value_file)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "aruco_dict = cv.aruco.Dictionary_get(cv.aruco.DICT_4X4_100)\n",
    "parameters = cv.aruco.DetectorParameters_create()\n",
    "\n",
    "corner_ids = [0, 1, 2, 3]   # Orden: 0=arriba izq, 1=arriba der, 2=abajo der, 3=abajo izq\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # Solo para el caso de video. Omitir con fotos.\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Corrección y detección de ArUco Marker:\n",
    "    if mtx is not None and dist is not None:\n",
    "        frame = calib_img(frame, mtx, dist)\n",
    "    corners, ids, _ = cv.aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    if ids is not None:\n",
    "        frame = cv.aruco.drawDetectedMarkers(frame, corners, ids)       # Solo visual\n",
    "\n",
    "        # Busqueda de corners:\n",
    "        ids = ids.flatten()\n",
    "        detected = {}\n",
    "\n",
    "        for i, marker_id in enumerate(ids):\n",
    "            # Obtengo centros solo de los corners ID:\n",
    "            if marker_id in corner_ids:\n",
    "                c = corners[i][0]\n",
    "                center_x, center_y = c[:,0].mean(), c[:,1].mean()\n",
    "                detected[marker_id] = (center_x, center_y)\n",
    "                cv.circle(frame, (int(center_x), int(center_y)), 5, (0,0,255), -1)  # Solo visual\n",
    "\n",
    "        if all(mid in detected for mid in corner_ids):\n",
    "            detected_points = np.array([\n",
    "                detected[0],  # arriba izq\n",
    "                detected[1],  # arriba der\n",
    "                detected[2],  # abajo der\n",
    "                detected[3]   # abajo izq\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "            # Tamaño deseado de salida (ejemplo: 600x600 px)\n",
    "            real_points = np.array([\n",
    "                [0, 0],                             # arriba izq\n",
    "                [image_size[0]-1, 0],               # arriba der\n",
    "                [image_size[0]-1, image_size[1]-1], # abajo der\n",
    "                [0, image_size[1]-1]                # abajo izq\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "            # Corrección de la imagen: \n",
    "            H, _ = cv.findHomography(detected_points, real_points)\n",
    "            aligned = cv.warpPerspective(frame, H, image_size)\n",
    "            print(f\"Imagen corregida con escala x:{scale[0]}, y:{scale[1]}\")\n",
    "            cv.imshow(\"Vista Alineada\", aligned)\n",
    "\n",
    "    cv.imshow(\"Camara\", frame)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
